{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a7dd655",
      "metadata": {
        "id": "4a7dd655"
      },
      "source": [
        "# ğŸ“ ë¯¸ì…˜ ë¬¸ì œì§€: í•œêµ­ì–´ BERT ê°ì„± ë¶„ë¥˜\n",
        "\n",
        "## ğŸ“œ ë°°ê²½ ìŠ¤í† ë¦¬\n",
        "ë‹¹ì‹ ì€ **â€œì½”ë”© ìš”ì • ì¹´ì¹´ë¼â€**ê°€ ì´ë„ëŠ” ìŠ¤íƒ€íŠ¸ì—… **â€œë§ˆìŒ ë²ˆì—­ì†Œâ€**ì˜ ì‹ ì… NLP ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.  \n",
        "ì˜í™” ë¦¬ë·° ì† íŒ¬ë“¤ì˜ ê°ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì½ì–´ ğŸ¿ **â€œíŒì½˜ ì§€ìˆ˜â€**ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì²« í”„ë¡œì íŠ¸ì— ì°©ìˆ˜í–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "### ëª©í‘œ\n",
        "1. **í•œêµ­ì–´ BERT**ë¥¼ íŒŒì¸íŠœë‹í•˜ì—¬ ë¦¬ë·°ì˜ ê¸Â·ë¶€ì •ì„ ë¶„ë¥˜í•œë‹¤.  \n",
        "2. ì‚¬ìš©ìê°€ í•œê¸€ ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´ ì¦‰ì‹œ ê°ì •ì„ ì˜ˆì¸¡í•˜ëŠ” **`predict_sentiment`** í•¨ìˆ˜ë¥¼ ì™„ì„±í•œë‹¤.  \n",
        "\n",
        "ëª¨ë“  ê³¼ì œëŠ” **PyTorch & Hugging Face Transformers** ìƒíƒœê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8625b981",
      "metadata": {
        "id": "8625b981"
      },
      "source": [
        "## ğŸ› ï¸ ê³¼ì œ ë‹¨ê³„\n",
        "| ë‹¨ê³„ | ë‚´ìš© | ì™„ë£Œ ì¡°ê±´ |\n",
        "|-----|------|-----------|\n",
        "|1|í™˜ê²½ ì„¤ì •, ë°ì´í„°ì…‹(NSMC) ë¡œë“œ|ì…€ ì‹¤í–‰ ê²°ê³¼ ë°ì´í„°ì…‹ ì •ë³´ ì¶œë ¥|\n",
        "|2|í† í°í™” ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ êµ¬í˜„|`encoded` ë°ì´í„°ì…‹ ìƒì„±|\n",
        "|3|BERT ë¶„ë¥˜ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° & `Trainer` ì„¤ì •|`Trainer` ì¸ìŠ¤í„´ìŠ¤ ìƒì„±|\n",
        "|4|ëª¨ë¸ í•™ìŠµ|í•™ìŠµ ë¡œê·¸ ì¶œë ¥ & ìµœì¢… ì—í­ ì™„ë£Œ|\n",
        "|5|ê²€ì¦Â·í…ŒìŠ¤íŠ¸ í‰ê°€|`accuracy` 0.75 ì´ìƒ ë‹¬ì„±|\n",
        "|6|ì‹¤ì‹œê°„ ì˜ˆì¸¡ í•¨ìˆ˜ ì‘ì„±|ì„ì˜ ë¬¸ì¥ 2ê°œ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥|\n",
        "\n",
        "> **íŒíŠ¸:** ê° ì½”ë“œ ë¸”ë¡ì˜ `### TODO` ë¶€ë¶„ì„ ì±„ìš°ë©´ ë©ë‹ˆë‹¤.  \n",
        "> ì „ì²´ ì½”ë“œì˜ **~50%**ëŠ” ì´ë¯¸ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6d05771",
      "metadata": {
        "id": "c6d05771"
      },
      "source": [
        "### 1ï¸âƒ£ í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4bc5d27b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bc5d27b",
        "outputId": "17b982e2-2bb8-4d93-fb06-12d4895543dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'document', 'label'],\n",
            "        num_rows: 150000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'document', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# ğŸš¨ ìµœì´ˆ 1íšŒë§Œ ì„¤ì¹˜ (ì£¼ì„ í•´ì œ í›„ ì‹¤í–‰)\n",
        "#!pip install -q transformers datasets accelerate tqdm\n",
        "#!pip install -U datasets huggingface_hub fsspec\n",
        "#!pip install evaluate\n",
        "#!pip install -U transformers datasets\n",
        "\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œ ê³ ì •\n",
        "import random, numpy as np, torch\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "set_seed()\n",
        "\n",
        "# NSMC (Naver Sentiment Movie Corpus) ë¡œë“œ\n",
        "dataset = load_dataset(\"nsmc\")\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "915cbc59",
      "metadata": {
        "id": "915cbc59"
      },
      "source": [
        "### 2ï¸âƒ£ í† í°í™” & ì „ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "37efe741",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37efe741",
        "outputId": "90923f74-3cbc-4a48-e628-8af01e6b0736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '9746412', 'document': 'ì´ê±´ë­ ì˜í™”ë„ì•„ë‹ˆë‹¤ ì¬ë¯¸ë„ì—†ëŠ”ëŒ€ ë¹„ì‹¸ê¸°ë§Œí•˜ê³  ì§œì¦ë‚˜ê²Œ ì¬ë¯¸ì—†ë„¤', 'labels': 0, 'input_ids': [2, 5370, 3005, 3771, 2119, 2227, 3606, 4697, 2119, 2899, 2259, 2104, 8092, 2015, 2154, 19521, 9801, 2075, 2318, 19113, 2203, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"klue/bert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    \"\"\"ë¬¸ì¥-> í† í° ID ë³€í™˜\"\"\"\n",
        "    return tokenizer(\n",
        "        batch[\"document\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "\n",
        "# map í•¨ìˆ˜ ì ìš© (batched=True)\n",
        "encoded = dataset.map(tokenize_fn, batched=True)\n",
        "encoded = encoded.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# ì‘ì€ ìƒ˜í”Œ ì„¸íŠ¸(í•™ìŠµ 5k/ê²€ì¦ 1k/í…ŒìŠ¤íŠ¸ 1k) ì„ íƒ\n",
        "small_train = encoded[\"train\"].shuffle(seed=0).select(range(5000))\n",
        "small_valid = encoded[\"train\"].shuffle(seed=1).select(range(1000))\n",
        "small_test  = encoded[\"test\"].shuffle(seed=2).select(range(1000))\n",
        "\n",
        "print(small_train[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3ï¸âƒ£ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° & Trainer ì„¤ì •"
      ],
      "metadata": {
        "id": "AiIak2y9U5jK"
      },
      "id": "AiIak2y9U5jK"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "12568b58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12568b58",
        "outputId": "fb1291cd-cde0-49dd-b431-bda8e70a29f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "\n",
        "# BERT ë¶„ë¥˜ ëª¨ë¸\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "# TrainingArguments (ì¼ë¶€ íŒŒë¼ë¯¸í„°ëŠ” ì±„ì›Œì ¸ ìˆìŒ)\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./bert-nsmc\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "\n",
        "args = TrainingArguments(\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "\n",
        "# ì •í™•ë„ metric\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=preds, references=labels)\n",
        "\n",
        "# TODO: Trainer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=small_train,\n",
        "    eval_dataset=small_valid,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89991ad1",
      "metadata": {
        "id": "89991ad1"
      },
      "source": [
        "### 4ï¸âƒ£ ëª¨ë¸ í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "37dee349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "37dee349",
        "outputId": "04c67efa-060a-43b5-c835-ba7034df03ec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Private W&B dashboard, no account required\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Private W&B dashboard, no account required'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-mouse-921091980337686677\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250526_064737-b6coht8p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anony-mouse-921091980337686677/uncategorized/runs/b6coht8p?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf' target=\"_blank\">youthful-cosmos-1</a></strong> to <a href='https://wandb.ai/anony-mouse-921091980337686677/uncategorized?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anony-mouse-921091980337686677/uncategorized?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf' target=\"_blank\">https://wandb.ai/anony-mouse-921091980337686677/uncategorized?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anony-mouse-921091980337686677/uncategorized/runs/b6coht8p?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf' target=\"_blank\">https://wandb.ai/anony-mouse-921091980337686677/uncategorized/runs/b6coht8p?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Do NOT share these links with anyone. They can be used to claim your runs."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1875/1875 23:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.408800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.277100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.180600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1875, training_loss=0.26171563517252605, metrics={'train_runtime': 1432.7327, 'train_samples_per_second': 10.47, 'train_steps_per_second': 1.309, 'total_flos': 3946665830400000.0, 'train_loss': 0.26171563517252605, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# TODO: trainer.train() í˜¸ì¶œ\n",
        "### TODO ###\n",
        "import wandb\n",
        "\n",
        "wandb.init(anonymous=\"allow\")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64613c13",
      "metadata": {
        "id": "64613c13"
      },
      "source": [
        "### 5ï¸âƒ£ ëª¨ë¸ í‰ê°€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7f1bdc53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "7f1bdc53",
        "outputId": "63a34b28-5518-4b54-a3e4-8c9eb5a1b72f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:29]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5807258486747742, 'eval_accuracy': 0.869, 'eval_runtime': 30.1636, 'eval_samples_per_second': 33.153, 'eval_steps_per_second': 4.144, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# TODO: trainer.evaluate() ë¡œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì •í™•ë„ ì¶œë ¥\n",
        "test_metrics = trainer.evaluate(eval_dataset=small_test)\n",
        "print(test_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "876dcec4",
      "metadata": {
        "id": "876dcec4"
      },
      "source": [
        "### 6ï¸âƒ£ ì‹¤ì‹œê°„ ì˜ˆì¸¡ í•¨ìˆ˜ êµ¬í˜„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "be8ffdcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be8ffdcd",
        "outputId": "cf393ba9-b870-4604-aeba-d3c22343593c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì´ ì˜í™” ì§„ì§œ ìµœê³ ë‹¤! -> {'label': 'ê¸ì • ğŸ˜ƒ', 'confidence': 0.9974000453948975}\n",
            "ì‹œê°„ ì•„ê¹ë‹¤... -> {'label': 'ë¶€ì • ğŸ˜', 'confidence': 0.9993352293968201}\n",
            "ê·¸ëƒ¥ ì£½ì–´ -> {'label': 'ë¶€ì • ğŸ˜', 'confidence': 0.9984160661697388}\n",
            "ì• ë§¤í•˜ë„¤ -> {'label': 'ë¶€ì • ğŸ˜', 'confidence': 0.9989583492279053}\n",
            "ê¸°ëŒ€ë§Œ ì•ˆí•˜ë©´... -> {'label': 'ê¸ì • ğŸ˜ƒ', 'confidence': 0.9021694660186768}\n"
          ]
        }
      ],
      "source": [
        "id2label = {0: \"ë¶€ì • ğŸ˜\", 1: \"ê¸ì • ğŸ˜ƒ\"}\n",
        "\n",
        "def predict_sentiment(sentence: str):\n",
        "    \"\"\"í•œê¸€ ë¬¸ì¥ â†’ ê°ì • ì˜ˆì¸¡ ê²°ê³¼ ë°˜í™˜\"\"\"\n",
        "    # ë¬¸ì¥ í† í°í™” (batchê°€ ì•„ë‹ˆë¼ ë‹¨ì¼ ë¬¸ì¥, tensorë¡œ ë°˜í™˜)\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "\n",
        "    # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ ì´ë™\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # ëª¨ë¸ ì¶”ë¡  (í‰ê°€ ëª¨ë“œ)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        confidence, pred_label_idx = torch.max(probs, dim=1)\n",
        "\n",
        "    label = id2label[int(pred_label_idx)]\n",
        "    confidence = float(confidence)\n",
        "\n",
        "    return {\"label\": label, \"confidence\": confidence}\n",
        "\n",
        "\n",
        "# ì„ì˜ ë¬¸ì¥ í…ŒìŠ¤íŠ¸\n",
        "for s in [\"ì´ ì˜í™” ì§„ì§œ ìµœê³ ë‹¤!\", \"ì‹œê°„ ì•„ê¹ë‹¤...\",\"ê·¸ëƒ¥ ì£½ì–´\",\"ì• ë§¤í•˜ë„¤\",\"ê¸°ëŒ€ë§Œ ì•ˆí•˜ë©´...\"]:\n",
        "    print(s, \"->\", predict_sentiment(s))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29fe66f4",
      "metadata": {
        "id": "29fe66f4"
      },
      "source": [
        "### ğŸ’¾ ì¶”ê°€ ê³¼ì œ(ì„ íƒ): ëª¨ë¸ ì €ì¥ & ë¡œë”©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "830ed5f6",
      "metadata": {
        "id": "830ed5f6"
      },
      "outputs": [],
      "source": [
        "# model.save_pretrained(\"./bert-nsmc-best\")\n",
        "# tokenizer.save_pretrained(\"./bert-nsmc-best\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d786ee2",
      "metadata": {
        "id": "2d786ee2"
      },
      "source": [
        "## ğŸ¯ ì œì¶œ ê¸°ì¤€\n",
        "- ëª¨ë“  `### TODO ###` ì˜ì—­ ì™„ì„±\n",
        "- í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì •í™•ë„ **â‰¥ 0.75**\n",
        "- `predict_sentiment` í•¨ìˆ˜ê°€ ë‘ ì˜ˆì‹œ ë¬¸ì¥ì„ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜\n",
        "\n",
        "### ë°ì´í„° ì¶œì²˜\n",
        "- NSMC: <https://huggingface.co/datasets/nsmc>\n",
        "\n",
        "> í–‰ìš´ì„ ë¹•ë‹ˆë‹¤! ì¹´ì¹´ë¼ê°€ ğŸ¿ íŒì½˜ ì§€ìˆ˜ë¥¼ ê¸°ë‹¤ë¦¬ê³  ìˆì–´ìš”.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}