{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a7dd655",
      "metadata": {
        "id": "4a7dd655"
      },
      "source": [
        "# üìù ÎØ∏ÏÖò Î¨∏Ï†úÏßÄ: ÌïúÍµ≠Ïñ¥ BERT Í∞êÏÑ± Î∂ÑÎ•ò\n",
        "\n",
        "## üìú Î∞∞Í≤Ω Ïä§ÌÜ†Î¶¨\n",
        "ÎãπÏã†ÏùÄ **‚ÄúÏΩîÎî© ÏöîÏ†ï Ïπ¥Ïπ¥Îùº‚Äù**Í∞Ä Ïù¥ÎÅÑÎäî Ïä§ÌÉÄÌä∏ÏóÖ **‚ÄúÎßàÏùå Î≤àÏó≠ÏÜå‚Äù**Ïùò Ïã†ÏûÖ NLP ÏóîÏßÄÎãàÏñ¥ÏûÖÎãàÎã§.  \n",
        "ÏòÅÌôî Î¶¨Î∑∞ ÏÜç Ìå¨Îì§Ïùò Í∞êÏ†ïÏùÑ Ïã§ÏãúÍ∞ÑÏúºÎ°ú ÏùΩÏñ¥ üçø **‚ÄúÌåùÏΩò ÏßÄÏàò‚Äù**Î•º ÏòàÏ∏°ÌïòÎäî Ï≤´ ÌîÑÎ°úÏ†ùÌä∏Ïóê Ï∞©ÏàòÌñàÏäµÎãàÎã§.\n",
        "\n",
        "### Î™©Ìëú\n",
        "1. **ÌïúÍµ≠Ïñ¥ BERT**Î•º ÌååÏù∏ÌäúÎãùÌïòÏó¨ Î¶¨Î∑∞Ïùò Í∏ç¬∑Î∂ÄÏ†ïÏùÑ Î∂ÑÎ•òÌïúÎã§.  \n",
        "2. ÏÇ¨Ïö©ÏûêÍ∞Ä ÌïúÍ∏Ä Î¨∏Ïû•ÏùÑ ÏûÖÎ†•ÌïòÎ©¥ Ï¶âÏãú Í∞êÏ†ïÏùÑ ÏòàÏ∏°ÌïòÎäî **`predict_sentiment`** Ìï®ÏàòÎ•º ÏôÑÏÑ±ÌïúÎã§.  \n",
        "\n",
        "Î™®Îì† Í≥ºÏ†úÎäî **PyTorch & Hugging Face Transformers** ÏÉùÌÉúÍ≥ÑÎ•º Í∏∞Î∞òÏúºÎ°ú ÏßÑÌñâÌï©ÎãàÎã§.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8625b981",
      "metadata": {
        "id": "8625b981"
      },
      "source": [
        "## üõ†Ô∏è Í≥ºÏ†ú Îã®Í≥Ñ\n",
        "| Îã®Í≥Ñ | ÎÇ¥Ïö© | ÏôÑÎ£å Ï°∞Í±¥ |\n",
        "|-----|------|-----------|\n",
        "|1|ÌôòÍ≤Ω ÏÑ§Ï†ï, Îç∞Ïù¥ÌÑ∞ÏÖã(NSMC) Î°úÎìú|ÏÖÄ Ïã§Ìñâ Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ïÎ≥¥ Ï∂úÎ†•|\n",
        "|2|ÌÜ†ÌÅ∞Ìôî Î∞è Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò Íµ¨ÌòÑ|`encoded` Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ±|\n",
        "|3|BERT Î∂ÑÎ•ò Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞ & `Trainer` ÏÑ§Ï†ï|`Trainer` Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±|\n",
        "|4|Î™®Îç∏ ÌïôÏäµ|ÌïôÏäµ Î°úÍ∑∏ Ï∂úÎ†• & ÏµúÏ¢Ö ÏóêÌè≠ ÏôÑÎ£å|\n",
        "|5|Í≤ÄÏ¶ù¬∑ÌÖåÏä§Ìä∏ ÌèâÍ∞Ä|`accuracy` 0.75 Ïù¥ÏÉÅ Îã¨ÏÑ±|\n",
        "|6|Ïã§ÏãúÍ∞Ñ ÏòàÏ∏° Ìï®Ïàò ÏûëÏÑ±|ÏûÑÏùò Î¨∏Ïû• 2Í∞ú ÏòàÏ∏° Í≤∞Í≥º Ï∂úÎ†•|\n",
        "\n",
        "> **ÌûåÌä∏:** Í∞Å ÏΩîÎìú Î∏îÎ°ùÏùò `### TODO` Î∂ÄÎ∂ÑÏùÑ Ï±ÑÏö∞Î©¥ Îê©ÎãàÎã§.  \n",
        "> Ï†ÑÏ≤¥ ÏΩîÎìúÏùò **~50%**Îäî Ïù¥ÎØ∏ Ï†úÍ≥µÎêòÏóàÏäµÎãàÎã§.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6d05771",
      "metadata": {
        "id": "c6d05771"
      },
      "source": [
        "### 1Ô∏è‚É£ ÌôòÍ≤Ω ÏÑ§Ï†ï Î∞è Îç∞Ïù¥ÌÑ∞ Î°úÎìú"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4bc5d27b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bc5d27b",
        "outputId": "17b982e2-2bb8-4d93-fb06-12d4895543dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'document', 'label'],\n",
            "        num_rows: 150000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'document', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# üö® ÏµúÏ¥à 1ÌöåÎßå ÏÑ§Ïπò (Ï£ºÏÑù Ìï¥Ï†ú ÌõÑ Ïã§Ìñâ)\n",
        "#!pip install -q transformers datasets accelerate tqdm\n",
        "#!pip install -U datasets huggingface_hub fsspec\n",
        "#!pip install evaluate\n",
        "#!pip install -U transformers datasets\n",
        "\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Ïû¨ÌòÑÏÑ±ÏùÑ ÏúÑÌï¥ ÏãúÎìú Í≥†Ï†ï\n",
        "import random, numpy as np, torch\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "set_seed()\n",
        "\n",
        "# NSMC (Naver Sentiment Movie Corpus) Î°úÎìú\n",
        "dataset = load_dataset(\"nsmc\")\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "915cbc59",
      "metadata": {
        "id": "915cbc59"
      },
      "source": [
        "### 2Ô∏è‚É£ ÌÜ†ÌÅ∞Ìôî & Ï†ÑÏ≤òÎ¶¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "37efe741",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37efe741",
        "outputId": "90923f74-3cbc-4a48-e628-8af01e6b0736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '9746412', 'document': 'Ïù¥Í±¥Î≠ê ÏòÅÌôîÎèÑÏïÑÎãàÎã§ Ïû¨ÎØ∏ÎèÑÏóÜÎäîÎåÄ ÎπÑÏã∏Í∏∞ÎßåÌïòÍ≥† ÏßúÏ¶ùÎÇòÍ≤å Ïû¨ÎØ∏ÏóÜÎÑ§', 'labels': 0, 'input_ids': [2, 5370, 3005, 3771, 2119, 2227, 3606, 4697, 2119, 2899, 2259, 2104, 8092, 2015, 2154, 19521, 9801, 2075, 2318, 19113, 2203, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"klue/bert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    \"\"\"Î¨∏Ïû•-> ÌÜ†ÌÅ∞ ID Î≥ÄÌôò\"\"\"\n",
        "    return tokenizer(\n",
        "        batch[\"document\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "\n",
        "# map Ìï®Ïàò Ï†ÅÏö© (batched=True)\n",
        "encoded = dataset.map(tokenize_fn, batched=True)\n",
        "encoded = encoded.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# ÏûëÏùÄ ÏÉòÌîå ÏÑ∏Ìä∏(ÌïôÏäµ 5k/Í≤ÄÏ¶ù 1k/ÌÖåÏä§Ìä∏ 1k) ÏÑ†ÌÉù\n",
        "small_train = encoded[\"train\"].shuffle(seed=0).select(range(5000))\n",
        "small_valid = encoded[\"train\"].shuffle(seed=1).select(range(1000))\n",
        "small_test  = encoded[\"test\"].shuffle(seed=2).select(range(1000))\n",
        "\n",
        "print(small_train[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3Ô∏è‚É£ Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞ & Trainer ÏÑ§Ï†ï"
      ],
      "metadata": {
        "id": "AiIak2y9U5jK"
      },
      "id": "AiIak2y9U5jK"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "12568b58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12568b58",
        "outputId": "fb1291cd-cde0-49dd-b431-bda8e70a29f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "\n",
        "# BERT Î∂ÑÎ•ò Î™®Îç∏\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "# TrainingArguments (ÏùºÎ∂Ä ÌååÎùºÎØ∏ÌÑ∞Îäî Ï±ÑÏõåÏ†∏ ÏûàÏùå)\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./bert-nsmc\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "\n",
        "args = TrainingArguments(\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "\n",
        "# Ï†ïÌôïÎèÑ metric\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=preds, references=labels)\n",
        "\n",
        "# TODO: Trainer Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=small_train,\n",
        "    eval_dataset=small_valid,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89991ad1",
      "metadata": {
        "id": "89991ad1"
      },
      "source": [
        "### 4Ô∏è‚É£ Î™®Îç∏ ÌïôÏäµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "37dee349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "37dee349",
        "outputId": "04c67efa-060a-43b5-c835-ba7034df03ec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Private W&B dashboard, no account required\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Private W&B dashboard, no account required'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-mouse-921091980337686677\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250526_064737-b6coht8p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anony-mouse-921091980337686677/uncategorized/runs/b6coht8p?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf' target=\"_blank\">youthful-cosmos-1</a></strong> to <a href='https://wandb.ai/anony-mouse-921091980337686677/uncategorized?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anony-mouse-921091980337686677/uncategorized?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf' target=\"_blank\">https://wandb.ai/anony-mouse-921091980337686677/uncategorized?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anony-mouse-921091980337686677/uncategorized/runs/b6coht8p?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf' target=\"_blank\">https://wandb.ai/anony-mouse-921091980337686677/uncategorized/runs/b6coht8p?apiKey=71d388a317d428c2488413b0a4fb3af99269adbf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Do NOT share these links with anyone. They can be used to claim your runs."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1875/1875 23:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.408800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.277100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.180600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1875, training_loss=0.26171563517252605, metrics={'train_runtime': 1432.7327, 'train_samples_per_second': 10.47, 'train_steps_per_second': 1.309, 'total_flos': 3946665830400000.0, 'train_loss': 0.26171563517252605, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# TODO: trainer.train() Ìò∏Ï∂ú\n",
        "### TODO ###\n",
        "import wandb\n",
        "\n",
        "wandb.init(anonymous=\"allow\")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64613c13",
      "metadata": {
        "id": "64613c13"
      },
      "source": [
        "### 5Ô∏è‚É£ Î™®Îç∏ ÌèâÍ∞Ä"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7f1bdc53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "7f1bdc53",
        "outputId": "63a34b28-5518-4b54-a3e4-8c9eb5a1b72f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:29]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5807258486747742, 'eval_accuracy': 0.869, 'eval_runtime': 30.1636, 'eval_samples_per_second': 33.153, 'eval_steps_per_second': 4.144, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# TODO: trainer.evaluate() Î°ú ÌÖåÏä§Ìä∏ ÏÑ∏Ìä∏ Ï†ïÌôïÎèÑ Ï∂úÎ†•\n",
        "test_metrics = trainer.evaluate(eval_dataset=small_test)\n",
        "print(test_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "876dcec4",
      "metadata": {
        "id": "876dcec4"
      },
      "source": [
        "### 6Ô∏è‚É£ Ïã§ÏãúÍ∞Ñ ÏòàÏ∏° Ìï®Ïàò Íµ¨ÌòÑ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "be8ffdcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be8ffdcd",
        "outputId": "cf393ba9-b870-4604-aeba-d3c22343593c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ïù¥ ÏòÅÌôî ÏßÑÏßú ÏµúÍ≥†Îã§! -> {'label': 'Í∏çÏ†ï üòÉ', 'confidence': 0.9974000453948975}\n",
            "ÏãúÍ∞Ñ ÏïÑÍπùÎã§... -> {'label': 'Î∂ÄÏ†ï üòû', 'confidence': 0.9993352293968201}\n",
            "Í∑∏ÎÉ• Ï£ΩÏñ¥ -> {'label': 'Î∂ÄÏ†ï üòû', 'confidence': 0.9984160661697388}\n",
            "Ïï†Îß§ÌïòÎÑ§ -> {'label': 'Î∂ÄÏ†ï üòû', 'confidence': 0.9989583492279053}\n",
            "Í∏∞ÎåÄÎßå ÏïàÌïòÎ©¥... -> {'label': 'Í∏çÏ†ï üòÉ', 'confidence': 0.9021694660186768}\n"
          ]
        }
      ],
      "source": [
        "id2label = {0: \"Î∂ÄÏ†ï üòû\", 1: \"Í∏çÏ†ï üòÉ\"}\n",
        "\n",
        "def predict_sentiment(sentence: str):\n",
        "    \"\"\"ÌïúÍ∏Ä Î¨∏Ïû• ‚Üí Í∞êÏ†ï ÏòàÏ∏° Í≤∞Í≥º Î∞òÌôò\"\"\"\n",
        "    # Î¨∏Ïû• ÌÜ†ÌÅ∞Ìôî (batchÍ∞Ä ÏïÑÎãàÎùº Îã®Ïùº Î¨∏Ïû•, tensorÎ°ú Î∞òÌôò)\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "\n",
        "    # GPU ÏÇ¨Ïö© Í∞ÄÎä•ÌïòÎ©¥ GPUÎ°ú Ïù¥Îèô\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Î™®Îç∏ Ï∂îÎ°† (ÌèâÍ∞Ä Î™®Îìú)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        confidence, pred_label_idx = torch.max(probs, dim=1)\n",
        "\n",
        "    label = id2label[int(pred_label_idx)]\n",
        "    confidence = float(confidence)\n",
        "\n",
        "    return {\"label\": label, \"confidence\": confidence}\n",
        "\n",
        "\n",
        "# ÏûÑÏùò Î¨∏Ïû• ÌÖåÏä§Ìä∏\n",
        "for s in [\"Ïù¥ ÏòÅÌôî ÏßÑÏßú ÏµúÍ≥†Îã§!\", \"ÏãúÍ∞Ñ ÏïÑÍπùÎã§...\",\"Í∑∏ÎÉ• Ï£ΩÏñ¥\",\"Ïï†Îß§ÌïòÎÑ§\",\"Í∏∞ÎåÄÎßå ÏïàÌïòÎ©¥...\"]:\n",
        "    print(s, \"->\", predict_sentiment(s))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29fe66f4",
      "metadata": {
        "id": "29fe66f4"
      },
      "source": [
        "### üíæ Ï∂îÍ∞Ä Í≥ºÏ†ú(ÏÑ†ÌÉù): Î™®Îç∏ Ï†ÄÏû• & Î°úÎî©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "830ed5f6",
      "metadata": {
        "id": "830ed5f6"
      },
      "outputs": [],
      "source": [
        "# model.save_pretrained(\"./bert-nsmc-best\")\n",
        "# tokenizer.save_pretrained(\"./bert-nsmc-best\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d786ee2",
      "metadata": {
        "id": "2d786ee2"
      },
      "source": [
        "## üéØ Ï†úÏ∂ú Í∏∞Ï§Ä\n",
        "- Î™®Îì† `### TODO ###` ÏòÅÏó≠ ÏôÑÏÑ±\n",
        "- ÌÖåÏä§Ìä∏ ÏÑ∏Ìä∏ Ï†ïÌôïÎèÑ **‚â• 0.75**\n",
        "- `predict_sentiment` Ìï®ÏàòÍ∞Ä Îëê ÏòàÏãú Î¨∏Ïû•ÏùÑ Ïò¨Î∞îÎ•¥Í≤å Î∂ÑÎ•ò\n",
        "\n",
        "### Îç∞Ïù¥ÌÑ∞ Ï∂úÏ≤ò\n",
        "- NSMC: <https://huggingface.co/datasets/nsmc>\n",
        "\n",
        "> ÌñâÏö¥ÏùÑ ÎπïÎãàÎã§! Ïπ¥Ïπ¥ÎùºÍ∞Ä üçø ÌåùÏΩò ÏßÄÏàòÎ•º Í∏∞Îã§Î¶¨Í≥† ÏûàÏñ¥Ïöî.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}