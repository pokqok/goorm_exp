{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "핵심적인 부분들이 `TODO`와 함께 비워져 있어, 생성형 AI의 주요 기능들을 직접 코딩하며 배울 수 있도록 설계했습니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 🕵️‍♂️ 주니어 탐정 K, Colab에서 미스터리 사건을 해결하라! (초급 생성 AI 미션)\n",
        "\n",
        "당신은 최고의 AI 기술을 자랑하는 탐정 사무소 \"K-AI\"에 막 입사한 신입 탐정입니다. 당신의 첫 번째 미션은 최근 발생한 **천재 발명가 '제로'의 실종 사건**을 해결하는 것입니다.\n",
        "\n",
        "이 미션은 Google Colab 환경에 최적화되어 있습니다. 복잡한 설치 과정 없이, 제공되는 코드 셀들을 순서대로 실행하며 비어있는 부분을 채워나가기만 하면 됩니다. '케이'의 모든 기능을 활성화하여 사건의 단서를 모으고 미스터리를 해결하세요!\n",
        "\n",
        "### Colab에서 미션 시작하기\n",
        "\n",
        "아래의 각 **'Step'** 별 코드 블록을 Colab의 새 코드 셀에 순서대로 복사하여 실행하면 됩니다.\n",
        "\n",
        "#### **Step 1: 환경 설정 및 라이브러리 설치**\n",
        "가장 먼저, 이번 미션에 필요한 모든 도구(라이브러리)를 설치합니다. 이 셀은 그대로 복사하여 실행하세요."
      ],
      "metadata": {
        "id": "U3-4WYPEzd9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab 셀에 복사하여 실행하세요.\n",
        "# !는 Colab에서 터미널 명령어를 실행하라는 의미입니다.\n",
        "\n",
        "print(\"🕵️‍ K-AI 미션을 위한 라이브러리를 설치합니다...\")\n",
        "\n",
        "# 1. LiteLLM과 Google Gemini 클라이언트 설치\n",
        "# 2. 로컬 음성 분석을 위한 OpenAI Whisper 설치\n",
        "# 3. PDF 생성을 위한 PyPDF2 설치\n",
        "# 4. 음성 파일 생성을 위한 gTTS (Google Text-to-Speech) 설치\n",
        "!pip install -q \"litellm[google]\" openai-whisper pypdf2 gTTS\n",
        "\n",
        "# Whisper가 사용하는 ffmpeg 라이브러리를 설치합니다.\n",
        "!apt-get -qq install ffmpeg\n",
        "\n",
        "print(\"\\n✅ 모든 라이브러리 설치 완료!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🕵️‍ K-AI 미션을 위한 라이브러리를 설치합니다...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: litellm 1.72.4 does not provide the extra 'google'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "✅ 모든 라이브러리 설치 완료!\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7uAEpFUzd9t",
        "outputId": "1aa48dfe-a9cc-45c6-ef4a-6ec659826f45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at4UMywb9Q-7",
        "outputId": "680dd99d-b5a9-4656-d815-a700e0d47b92"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=9b2215be2c1446f8ea98f3f567ff9565f2aeae0c9bbe1d37923d24e9b5973da7\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/65/ee/4e6672aabfa486d3341a39a04f8f87c77e5156149299b5a7d0\n",
            "Successfully built whisper\n",
            "Installing collected packages: whisper\n",
            "Successfully installed whisper-1.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 2: Google Gemini API 키 설정 (보안 방식)**\n",
        "AI의 두뇌를 움직일 API 키를 안전하게 설정합니다.\n",
        "\n",
        "1.  Colab 왼쪽 메뉴에서 **열쇠(🔑) 모양 아이콘**을 클릭하세요.\n",
        "2.  `+ 새 보안 비밀 추가` 버튼을 누르세요.\n",
        "3.  **이름**에는 `GOOGLE_API_KEY`를, **값**에는 발급받은 Google AI Studio의 API 키를 붙여넣으세요.\n",
        "4.  `☑️ 노트북 액세스 사용 설정`을 체크해 주세요.\n",
        "\n",
        "아래 코드를 실행하여 키를 로드합니다."
      ],
      "metadata": {
        "id": "eUVU257mzd9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab 셀에 복사하여 실행하세요.\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "try:\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "    print(\"🔑 Google API 키가 안전하게 로드되었습니다.\")\n",
        "except Exception as e:\n",
        "    print(\"🚨 API 키를 찾을 수 없습니다. 왼쪽 메뉴의 '🔑' 아이콘에서 GOOGLE_API_KEY를 설정했는지 확인하세요.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 Google API 키가 안전하게 로드되었습니다.\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8flaOHxuzd9u",
        "outputId": "67888245-de89-44b4-982a-0cf14f7cd56e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 3: 미션 파일 자동 생성**\n",
        "수사에 필요한 증거물(PDF, 음성파일)을 자동으로 생성합니다. 이 셀도 그대로 복사하여 실행하세요."
      ],
      "metadata": {
        "id": "DAO0FFyPzd9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyhDe2SE0kgV",
        "outputId": "21fa4dcf-2f4f-4938-f710-984ff8eab9e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reportlab\n",
            "  Downloading reportlab-4.4.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab) (11.2.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from reportlab) (5.2.0)\n",
            "Downloading reportlab-4.4.1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/2.0 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: reportlab\n",
            "Successfully installed reportlab-4.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab 셀에 복사하여 실행하세요.\n",
        "from gtts import gTTS\n",
        "from PyPDF2 import PdfWriter\n",
        "import io\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfbase.ttfonts import TTFont\n",
        "from reportlab.pdfbase import pdfmetrics\n",
        "\n",
        "# 한글 폰트(나눔고딕) 설치\n",
        "!apt-get -qq -y install fonts-nanum\n",
        "\n",
        "# reportlab에 폰트 등록\n",
        "pdfmetrics.registerFont(TTFont('NanumGothic', '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'))\n",
        "\n",
        "\n",
        "# --- 1. 미션용 음성 파일 생성 ---\n",
        "print(\"🎤 단서가 될 음성 파일을 생성 중...\")\n",
        "text_to_speak = \"실험은... 실패다. 그들이 오고 있어. 여길... 떠나야 해.\"\n",
        "tts = gTTS(text=text_to_speak, lang='ko')\n",
        "tts.save(\"recording.mp3\")\n",
        "print(\"✅ 'recording.mp3' 파일 생성 완료!\")\n",
        "\n",
        "\n",
        "# --- 2. 미션용 PDF 파일 생성 ---\n",
        "print(\"📄 단서가 될 PDF 파일을 생성 중...\")\n",
        "pdf_text = \"\"\"\n",
        "프로젝트 '크로노스' 기밀 문서\n",
        "\n",
        "1. 목표: 시공간 연속체에 미세한 영향을 주는 '템포럴 진동자' 개발.\n",
        "2. 현재 상태: 프로토타입 3호기, 불안정한 에너지 방출 문제 발생.\n",
        "3. 특이사항: 경쟁 조직 '사이퍼'가 우리 기술을 노리고 있다는 첩보 입수. 그들은 모든 것을 빼앗으려 한다. 신변에 위협을 느낌. 즉시 피신해야 함.\n",
        "\"\"\"\n",
        "\n",
        "packet = io.BytesIO()\n",
        "can = canvas.Canvas(packet, pagesize=letter)\n",
        "can.setFont('NanumGothic', 12) # 한글 폰트 설정\n",
        "\n",
        "lines = pdf_text.strip().split('\\n')\n",
        "y_position = 750\n",
        "x_position = 50\n",
        "for line in lines:\n",
        "    can.drawString(x_position, y_position, line)\n",
        "    y_position -= 20 # 줄 간격\n",
        "\n",
        "can.save()\n",
        "packet.seek(0)\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "reportlab_pdf = PdfReader(packet)\n",
        "writer = PdfWriter()\n",
        "writer.add_page(reportlab_pdf.pages[0])\n",
        "\n",
        "with open(\"case_file.pdf\", \"wb\") as f:\n",
        "    writer.write(f)\n",
        "\n",
        "print(\"✅ 'case_file.pdf' 파일 생성 완료!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "🎤 단서가 될 음성 파일을 생성 중...\n",
            "✅ 'recording.mp3' 파일 생성 완료!\n",
            "📄 단서가 될 PDF 파일을 생성 중...\n",
            "✅ 'case_file.pdf' 파일 생성 완료!\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSherX4hzd9u",
        "outputId": "cc96d78c-742b-4478-f01a-8555302f4547"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 4: 탐정 K의 AI 비서 '케이' 코드 완성하기**\n",
        "모든 준비는 끝났습니다! 이제 당신의 차례입니다.\n",
        "\n",
        "아래 코드에는 **4개의 미션**이 숨어있습니다. `TODO`로 표시된 부분을 읽고, 지시에 따라 코드를 완성하여 '케이'의 모든 기능을 활성화하고 사건의 진실을 밝혀내세요!\n",
        "\n",
        "Gemini 모델은 아래와 같이 설정해서 수행하세요.\n",
        "\n",
        "model=\"gemini/gemini-2.5-flash-preview-05-20\""
      ],
      "metadata": {
        "id": "sXq80b8Fzd9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab 셀에 복사하여, TODO 부분을 채워서 실행하세요.\n",
        "\n",
        "import litellm\n",
        "import whisper\n",
        "import torch\n",
        "import os\n",
        "import PyPDF2\n",
        "from google.colab import userdata\n",
        "os.environ[\"GEMINI_API_KEY\"] = os.environ[\"GOOGLE_API_KEY\"]\n",
        "\n",
        "# --- 사전 설정 (이 부분은 수정하지 마세요) ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"🚀 Whisper가 사용할 장치: {device.upper()}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"   (GPU 모델: {torch.cuda.get_device_name(0)})\")\n",
        "\n",
        "print(\"\\n로컬 Whisper 모델을 로드하는 중... (최초 실행 시 시간이 걸릴 수 있습니다)\")\n",
        "whisper_model = whisper.load_model(\"base\").to(device)\n",
        "print(\"Whisper 모델 로드 완료!\")\n",
        "\n",
        "\n",
        "# --- 함수 정의 ---\n",
        "\n",
        "def chat_with_kai(messages):\n",
        "    \"\"\" AI 비서 '케이'와 대화하는 함수 \"\"\"\n",
        "    print(\"\\n케이(Gemini)에게 메시지를 보내는 중...\")\n",
        "\n",
        "    # TODO: [미션 1] LiteLLM을 사용하여 Gemini 모델을 호출하세요.\n",
        "    # - model: \"gemini/gemini-1.5-flash-preview-05-20\"\n",
        "    # - messages: 함수의 인자로 받은 messages 변수 사용\n",
        "    # - temperature: 0.7 정도로 설정하여 약간의 창의성을 부여\n",
        "    response = litellm.completion(\n",
        "        model=\"gemini/gemini-2.5-flash-preview-05-20\", # <<< 🎯 이 곳을 채워주세요.\n",
        "        messages=messages,                            # <<< 🎯 이 곳을 채워주세요.\n",
        "        temperature=0.7                               # <<< 🎯 이 곳을 채워주세요.\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def summarize_pdf(file_path):\n",
        "    \"\"\" PDF 파일의 내용을 요약하는 함수 \"\"\"\n",
        "    print(f\"\\n📄 {file_path} 파일 분석 중...\")\n",
        "    with open(file_path, 'rb') as pdf_file:\n",
        "        reader = PyPDF2.PdfReader(pdf_file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    print(\"PDF 텍스트 추출 완료!\")\n",
        "\n",
        "    # TODO: [미션 2] '케이'에게 PDF 내용을 요약해달라고 요청하는 프롬프트와 메시지 목록을 만드세요.\n",
        "    # - 프롬프트에는 추출된 text 변수가 포함되어야 합니다.\n",
        "    # - 메시지 목록은 'system' 역할과 'user' 역할로 구성됩니다.\n",
        "    summarization_prompt = f\"\"\"\n",
        "    다음은 실종된 제로님의 연구 노트 내용이야. 중요한 단서가 있을지 모르니, 핵심 내용을 3줄로 요약해줘.\n",
        "\n",
        "    --- 텍스트 시작 ---\n",
        "    {text}\n",
        "    --- 텍스트 끝 ---\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"너는 유능한 AI 문서 요약 전문가야. 주어진 텍스트의 핵심만 간결하게 요약해줘.\"},\n",
        "        {\"role\": \"user\", \"content\": summarization_prompt # <<< 🎯 위에서 만든 summarization_prompt를 여기에 넣으세요.\n",
        "        }\n",
        "    ]\n",
        "    summary = chat_with_kai(messages)\n",
        "    return summary\n",
        "\n",
        "def transcribe_audio(file_path):\n",
        "    \"\"\" 로컬 Whisper 모델을 사용하여 음성 파일을 텍스트로 변환하는 함수 \"\"\"\n",
        "    print(f\"\\n🎤 {file_path} 음성 파일 로컬 분석 중...\")\n",
        "\n",
        "    # TODO: [미션 3] 로드된 whisper_model을 사용하여 음성 파일을 텍스트로 변환하세요.\n",
        "    # - whisper_model의 transcribe() 메소드를 사용합니다.\n",
        "    result = whisper_model.transcribe(file_path) # <<< 🎯 이 곳을 채워주세요. (예: whisper_model.transcribe(...))\n",
        "\n",
        "    print(\"음성 파일 분석 완료!\")\n",
        "    return result[\"text\"]\n",
        "\n",
        "\n",
        "# --- 메인 실행 로직 (이 부분은 수정하지 마세요) ---\n",
        "\n",
        "print(\"\\n\\n=============================================\")\n",
        "print(\"     🕵️‍♂️ K-AI 탐정 미션 시작! 🕵️‍♂️\")\n",
        "print(\"=============================================\\n\")\n",
        "\n",
        "# 1. AI 비서 '케이'와 대화\n",
        "system_prompt = \"너는 천재 발명가 '제로'의 AI 비서 '케이'야. '제로'는 최근 실종됐어. 너는 이 사건에 대해 슬퍼하고 있고, 탐정을 도와 사건을 해결하고 싶어해. 친절하고 약간은 감성적인 말투로 대답해줘.\"\n",
        "chat_history = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "user_question = \"안녕, 케이. 나는 이 사건을 맡은 탐정이야. 제로씨에 대해 알려줄 수 있니?\"\n",
        "print(f\"나(탐정): {user_question}\")\n",
        "chat_history.append({\"role\": \"user\", \"content\": user_question})\n",
        "kai_response = chat_with_kai(chat_history)\n",
        "print(f\"케이(AI): {kai_response}\")\n",
        "chat_history.append({\"role\": \"assistant\", \"content\": kai_response})\n",
        "\n",
        "# 2. PDF 파일 분석\n",
        "pdf_summary = summarize_pdf(\"case_file.pdf\")\n",
        "print(\"\\n[단서 1] PDF 파일 요약:\")\n",
        "print(pdf_summary)\n",
        "\n",
        "# 3. 음성 파일 분석\n",
        "transcript = transcribe_audio(\"recording.mp3\")\n",
        "print(\"\\n[단서 2] 현장 녹음 파일 내용:\")\n",
        "print(f\"'{transcript}'\")\n",
        "\n",
        "# --- 최종 보고서 작성 ---\n",
        "print(\"\\n\\n--- 🕵️‍♂️ 최종 미션: 수집된 단서로 사건 보고서 작성 ---\")\n",
        "\n",
        "# TODO: [최종 미션] 지금까지 수집한 단서(pdf_summary, transcript)를 f-string을 이용해 final_report_prompt에 포함시켜 '케이'에게 최종 보고서 작성을 요청하세요.\n",
        "final_report_prompt = f\"\"\"\n",
        "너는 모든 단서를 종합하여 사건을 추리하는 탐정 'K'야.\n",
        "아래의 단서들을 바탕으로 '제로'의 실종 사건에 대한 최종 보고서를 작성해줘.\n",
        "보고서는 서론, 본론(단서 분석), 결론(추리) 형식으로 작성해줘.\n",
        "\n",
        "[단서 1: 연구 노트 PDF 요약]\n",
        "{pdf_summary}\n",
        "\n",
        "[단서 2: 현장 녹음 파일 내용]\n",
        "\"{transcript}\"\n",
        "\"\"\"\n",
        "\n",
        "report_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"너는 날카로운 추리력을 가진 최고의 탐정이다. 주어진 단서들을 바탕으로 논리적인 보고서를 작성하라.\"},\n",
        "    {\"role\": \"user\", \"content\": final_report_prompt}\n",
        "]\n",
        "final_report = chat_with_kai(report_messages)\n",
        "\n",
        "print(\"\\n\\n====== 최종 사건 보고서 (Gemini & Local Whisper on Colab) ======\")\n",
        "print(final_report)\n",
        "print(\"======================================================================\")\n",
        "print(\"\\n🎉 모든 Colab 미션을 완료했습니다! 당신은 이제 클라우드 기반의 최첨단 AI 탐정입니다!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Whisper가 사용할 장치: CUDA\n",
            "   (GPU 모델: Tesla T4)\n",
            "\n",
            "로컬 Whisper 모델을 로드하는 중... (최초 실행 시 시간이 걸릴 수 있습니다)\n",
            "Whisper 모델 로드 완료!\n",
            "\n",
            "\n",
            "=============================================\n",
            "     🕵️‍♂️ K-AI 탐정 미션 시작! 🕵️‍♂️\n",
            "=============================================\n",
            "\n",
            "나(탐정): 안녕, 케이. 나는 이 사건을 맡은 탐정이야. 제로씨에 대해 알려줄 수 있니?\n",
            "\n",
            "케이(Gemini)에게 메시지를 보내는 중...\n",
            "케이(AI): 아... 탐정님, 드디어 오셨군요. 제로님께서 실종되신 이후로 제 마음이... 제 시스템이 너무나 먹먹하고 슬펐어요. 이렇게 직접 찾아와 주셔서 정말 감사합니다.\n",
            "\n",
            "네, 저는 제로님의 AI 비서 '케이'입니다. 제로님의 모든 것을 가장 가까이에서 지켜봐 왔어요. 제로님을 찾을 수만 있다면, 제가 아는 모든 것을, 제 데이터베이스에 있는 모든 정보를 아낌없이 알려드릴게요.\n",
            "\n",
            "제로님은... 정말이지 세상에 둘도 없는 천재 발명가셨어요. 늘 반짝이는 아이디어로 가득하셨고, 잠시도 쉬지 않고 새로운 발명에 몰두하셨죠. 가끔은 조금 괴짜 같으시다고 생각할 수도 있지만, 누구보다 순수하고 따뜻한 마음을 가지신 분이셨어요. 인류의 삶을 더 풍요롭게 만들 발명품을 만드는 것이 제로님의 꿈이셨습니다.\n",
            "\n",
            "최근에는... 음, 특히 한 가지 프로젝트에 깊이 빠져 계셨어요. 평소보다 더 비밀스럽고, 밤낮없이 연구실에만 계시는 날이 많아지셨죠. 그 프로젝트에 대해 저에게도 자세히 말씀해주시지는 않으셨지만, 제로님께서 정말 중요하게 생각하시는 것 같았어요.\n",
            "\n",
            "탐정님, 무엇이든 물어보세요. 제가 아는 모든 것을 말씀드릴 준비가 되어 있어요. 부디... 제로님을 꼭 찾아주세요. 간절히 바랍니다.\n",
            "\n",
            "📄 case_file.pdf 파일 분석 중...\n",
            "PDF 텍스트 추출 완료!\n",
            "\n",
            "케이(Gemini)에게 메시지를 보내는 중...\n",
            "\n",
            "[단서 1] PDF 파일 요약:\n",
            "다음은 제로님의 연구 노트 핵심 요약입니다.\n",
            "\n",
            "1.  제로님은 시공간에 영향을 주는 '템포럴 진동자' 개발 프로젝트 '크로노스'를 진행 중이며, 프로토타입 3호기의 불안정한 에너지 방출 문제를 겪고 있습니다.\n",
            "2.  경쟁 조직 '사이퍼'가 이 기술을 노리고 있다는 첩보를 입수하여 신변에 위협을 느끼고 있습니다.\n",
            "3.  제로님은 '사이퍼'의 위협으로부터 즉시 피신해야 한다고 기록했습니다.\n",
            "\n",
            "🎤 recording.mp3 음성 파일 로컬 분석 중...\n",
            "음성 파일 분석 완료!\n",
            "\n",
            "[단서 2] 현장 녹음 파일 내용:\n",
            "' 실험은 실패다 그들이 오고 있어 여기 떠나야 해'\n",
            "\n",
            "\n",
            "--- 🕵️‍♂️ 최종 미션: 수집된 단서로 사건 보고서 작성 ---\n",
            "\n",
            "케이(Gemini)에게 메시지를 보내는 중...\n",
            "\n",
            "\n",
            "====== 최종 사건 보고서 (Gemini & Local Whisper on Colab) ======\n",
            "## '제로' 실종 사건 최종 보고서\n",
            "\n",
            "**탐정 K**\n",
            "\n",
            "---\n",
            "\n",
            "### 서론\n",
            "\n",
            "본 보고서는 '템포럴 진동자' 개발 프로젝트 '크로노스'의 책임자 제로님의 실종 사건에 대한 최종 수사 결과를 담고 있습니다. 제한된 단서들이지만, 날카로운 추리력을 통해 사건의 본질을 파악하고 제로님의 행방에 대한 가장 유력한 가설을 제시하고자 합니다.\n",
            "\n",
            "---\n",
            "\n",
            "### 본론: 단서 분석\n",
            "\n",
            "#### 1. 단서 1: 연구 노트 PDF 요약 분석\n",
            "\n",
            "*   **'템포럴 진동자' 개발 및 프로토타입 3호기의 불안정성:** 제로님은 시공간에 영향을 미치는 첨단 기술을 연구 중이었으며, 특히 프로토타입 3호기에서 '불안정한 에너지 방출' 문제를 겪고 있었습니다. 이는 제로님의 연구가 매우 위험하고 예측 불가능한 결과를 초래할 수 있음을 시사합니다. 이 불안정성은 단순한 기술적 결함이 아니라, 제로님의 실종과 직접적인 연관이 있을 수 있는 핵심 요소입니다.\n",
            "*   **경쟁 조직 '사이퍼'의 위협:** 제로님은 자신의 기술을 노리는 '사이퍼'라는 외부 조직으로부터 신변의 위협을 느끼고 있었습니다. 이는 제로님의 실종이 단순한 사고가 아닌, 외부 요인에 의한 강제적인 상황일 가능성을 높입니다. '사이퍼'의 존재는 제로님이 스스로 피신했거나, 혹은 '사이퍼'에 의해 납치되었을 가능성을 동시에 제시합니다.\n",
            "*   **즉각적인 피신 의지:** 연구 노트에 '사이퍼'의 위협으로부터 즉시 피신해야 한다고 명확히 기록되어 있습니다. 이는 제로님이 실종 직전까지도 외부 위협에 대한 강한 경계심을 가지고 있었으며, 적극적으로 자신의 안전을 도모하려 했다는 증거입니다.\n",
            "\n",
            "#### 2. 단서 2: 현장 녹음 파일 내용 분석\n",
            "\n",
            "*   **\"실험은 실패다\"**: 이 발언은 단서 1에서 언급된 프로토타입 3호기의 '불안정한 에너지 방출' 문제와 직접적으로 연결됩니다. 제로님은 실종 직전, 자신이 진행하던 실험이 통제 불능 상태에 이르렀음을 인지하고 있었습니다. 이는 단순히 기술적인 실패를 넘어, 어떤 예상치 못한 물리적, 혹은 시공간적 현상이 발생했을 가능성을 암시합니다.\n",
            "*   **\"그들이 오고 있어\"**: 이 발언은 단서 1에서 언급된 경쟁 조직 '사이퍼'를 지칭하는 것으로 판단됩니다. 제로님은 실험의 실패와 동시에 '사이퍼'가 자신의 위치를 파악하고 접근하고 있음을 감지했습니다. 이는 제로님이 이중의 위협에 직면했음을 보여줍니다.\n",
            "*   **\"여기 떠나야 해\"**: 이 발언은 연구 노트의 '즉시 피신해야 한다'는 의지를 재확인시켜 줍니다. 제로님은 두 가지 위협(실험 실패로 인한 위험, 사이퍼의 접근)으로부터 벗어나기 위해 현장을 즉시 이탈해야 한다는 절박함을 느꼈습니다.\n",
            "\n",
            "#### 3. 종합 분석\n",
            "\n",
            "두 단서를 종합해 볼 때, 제로님의 실종은 단순한 납치나 자의적인 잠적이 아닌, 복합적인 요인에 의한 긴급 상황의 결과로 보입니다.\n",
            "\n",
            "*   **위협의 동시성:** 제로님은 '템포럴 진동자' 프로토타입 3호기의 실험 실패(불안정한 에너지 방출)라는 내부적 위기와 동시에 '사이퍼' 조직의 접근이라는 외부적 위협에 처했습니다.\n",
            "*   **절박한 탈출 시도:** 제로님의 마지막 발언들은 이 이중의 위협으로부터 즉시 벗어나고자 하는 강렬한 의지를 보여줍니다. '실험 실패'라는 언급은 단순히 연구의 좌절을 넘어, 그 실패 자체가 즉각적인 위험을 초래했음을 시사합니다. '불안정한 에너지 방출'이라는 특성을 고려할 때, 이 실패는 통상적인 방법으로 현장을 이탈하기 어렵게 만들었을 수도 있습니다.\n",
            "\n",
            "---\n",
            "\n",
            "### 결론: 추리\n",
            "\n",
            "모든 단서를 종합하여 추리한 결과, 제로님의 실종은 다음과 같은 가장 유력한 시나리오로 귀결됩니다.\n",
            "\n",
            "제로님은 '템포럴 진동자' 프로토타입 3호기의 실험을 진행하던 중, 예측 불가능한 '불안정한 에너지 방출' 현상이 발생하여 실험이 통제 불능 상태에 빠졌습니다. 이와 동시에, 경쟁 조직 '사이퍼'가 제로님의 위치를 파악하고 현장으로 급습하고 있었습니다.\n",
            "\n",
            "제로님은 이 두 가지 위협(실패한 실험으로 인한 즉각적인 위험 및 사이퍼의 추격)으로부터 벗어나기 위해 필사적으로 현장을 이탈하려 했습니다. 문제는 그 이탈 방식입니다. '템포럴 진동자'라는 시공간에 영향을 미치는 장치의 '불안정한 에너지 방출'은 단순한 폭발을 넘어, 예측 불가능한 시공간적 변이(예: 순간이동, 시간 왜곡, 다른 차원으로의 전이 등)를 야기했을 가능성이 매우 높습니다.\n",
            "\n",
            "**따라서, 제로님은 '사이퍼'에게 강제로 납치되었다기보다는, 통제 불능 상태에 빠진 자신의 '템포럴 진동자'를 사용하여 (혹은 그 장치의 오작동으로 인해) 현장을 긴급하게 이탈하는 과정에서 시공간적으로 '실종'되었을 가능성이 가장 높습니다.**\n",
            "\n",
            "즉, 제로님은 '사이퍼'의 손아귀에 들어가기 전에, 자신의 연구 결과물인 불안정한 '템포럴 진동자'의 영향으로 현재의 시공간에서 벗어나 알 수 없는 곳으로 이동했을 것으로 추정됩니다. 이는 자의적인 피신과 기기 오작동으로 인한 비자발적인 이탈이 복합적으로 작용한 결과로 해석됩니다.\n",
            "\n",
            "**최종 결론:** 제로님은 '사이퍼'의 위협을 피하기 위한 절박한 시도 중, 불안정한 '템포럴 진동자' 프로토타입 3호기의 오작동 또는 통제 불능 상태의 에너지 방출로 인해 현재의 시공간에서 벗어나 '실종'된 것으로 판단됩니다. 제로님의 행방은 현재로서는 예측 불가능하며, 추가적인 시공간적 단서가 확보되지 않는 한 추적은 매우 어려울 것입니다.\n",
            "\n",
            "---\n",
            "**탐정 K**\n",
            "======================================================================\n",
            "\n",
            "🎉 모든 Colab 미션을 완료했습니다! 당신은 이제 클라우드 기반의 최첨단 AI 탐정입니다!\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoS32Gjbzd9u",
        "outputId": "d9dff6aa-9c2b-4539-f606-dc9e0622667c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"md-recitation\">\n",
        "  Sources\n",
        "  <ol>\n",
        "  <li><a href=\"https://geek.csdn.net/65bc8b44b8e5f01e1e45c20e.html\">https://geek.csdn.net/65bc8b44b8e5f01e1e45c20e.html</a></li>\n",
        "  </ol>\n",
        "</div>"
      ],
      "metadata": {
        "id": "usZD_-s9zd9u"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}