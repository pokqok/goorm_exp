{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1e0f4dde",
      "metadata": {
        "id": "1e0f4dde"
      },
      "source": [
        "\n",
        "# ğŸ“ ì´ˆê¸‰ ë”¥ëŸ¬ë‹ ë¯¸ì…˜:\n",
        "# ë”¥ëŸ¬ë‹ í•™êµ â€“ ë§ˆë²• ì‹ ê²½ë§ìœ¼ë¡œ ì„¸ê³„ë¥¼ êµ¬í•˜ë¼!\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ° ë°°ê²½ ìŠ¤í† ë¦¬\n",
        "\n",
        "ë‹¹ì‹ ì€ **AI ë§ˆë²•í•™êµì˜ ì…í•™ìƒ**ì…ë‹ˆë‹¤.  \n",
        "ì´ í•™êµì—ì„œëŠ” ì‚¬ëŒì˜ ê°ì •, ë‚ ì”¨, ì§ˆë³‘ì„ ì˜ˆì¸¡í•˜ëŠ” **ë§ˆë²• ì‹ ê²½ë§**ì„ ìˆ˜ë ¨í•©ë‹ˆë‹¤.  \n",
        "ë‹¹ì‹ ì˜ ì²« ìˆ˜ì—…ì€ **ë”¥ëŸ¬ë‹ ê¸°ì´ˆ ìˆ˜ë ¨**ì…ë‹ˆë‹¤.  \n",
        "ë‹¹ì‹ ì€ NumPyë§Œìœ¼ë¡œ **ë§ˆë²• ì‹ ê²½ë§**ì„ ì§ì ‘ êµ¬í˜„í•˜ê³ , ë‹¤ì–‘í•œ ë§ˆë²•ì„œ(Optimizer)ë¥¼ ì‹¤í—˜í•˜ë©°,  \n",
        "ë§ˆì§€ë§‰ì—” **PyTorch ë§ˆë²• ì‹œìŠ¤í…œ**ì— ì…ë¬¸í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ ë¯¸ì…˜ í•™ìŠµ ëª©í‘œ\n",
        "\n",
        "- ë”¥ëŸ¬ë‹ êµ¬ì¡° ë° ì›ë¦¬ ì´í•´ (forward, loss, backward)\n",
        "- í•™ìŠµë¥  ê°œë… ì‹¤í—˜\n",
        "- ì˜µí‹°ë§ˆì´ì € ì¢…ë¥˜ ë¹„êµ (SGD, Momentum, RMSProp, Adam)\n",
        "- íŒŒì´í† ì¹˜ ê¸°ì´ˆ ë¬¸ë²• í•™ìŠµ ë° ë¹„êµ\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© ë¯¸ì…˜ êµ¬ì„±\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95496ac7",
      "metadata": {
        "id": "95496ac7"
      },
      "source": [
        "\n",
        "### âœ… Part 1. ë”¥ëŸ¬ë‹ ê°œìš” í€´ì¦ˆ\n",
        "\n",
        "1. ë”¥ëŸ¬ë‹ì—ì„œ 'ì‹ ê²½ë§'ì´ë€ ë¬´ì—‡ì„ ëª¨ë°©í•œ ê²ƒì¸ê°€ìš”?  \n",
        "   a. ì»´í“¨í„° íšŒë¡œ  \n",
        "   b. ì¸ê°„ ë‡Œì˜ ë‰´ëŸ° êµ¬ì¡°  \n",
        "   c. ìˆ˜í•™ ê³µì‹  \n",
        "   d. ë¡œë´‡ ì œì–´ê¸°\n",
        "\n",
        "2. Backpropagationì€ ë¬´ì—‡ì„ ê³„ì‚°í•˜ëŠ” ê³¼ì •ì¸ê°€ìš”?  \n",
        "   a. ë°ì´í„° ì „ì²˜ë¦¬  \n",
        "   b. ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”  \n",
        "   c. ì†ì‹¤ í•¨ìˆ˜ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì—­ë°©í–¥ìœ¼ë¡œ ê³„ì‚°  \n",
        "   d. ì˜ˆì¸¡ê°’ì„ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b683bf32",
      "metadata": {
        "id": "b683bf32"
      },
      "source": [
        "b,c"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f93b89c4",
      "metadata": {
        "id": "f93b89c4"
      },
      "source": [
        "\n",
        "### âœ… Part 2. NumPy ê¸°ë°˜ ì‹ ê²½ë§ ì‹¤ìŠµ\n",
        "\n",
        "#### ğŸ¯ ë¬¸ì œ: XOR ë¬¸ì œë¥¼ NumPyë§Œìœ¼ë¡œ í‘¸ëŠ” 2ì¸µ ì‹ ê²½ë§ì„ ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”.\n",
        "\n",
        "- ì…ë ¥: 2ì°¨ì› ë²¡í„° (ex: [0,1], [1,1])\n",
        "- ì¶œë ¥: 0 ë˜ëŠ” 1\n",
        "- êµ¬ì¡°: ì…ë ¥(2) â†’ ì€ë‹‰ì¸µ(4, ReLU) â†’ ì¶œë ¥ì¸µ(1, Sigmoid)\n",
        "- ì†ì‹¤ í•¨ìˆ˜: Binary Cross Entropy\n",
        "\n",
        "#### âœï¸ êµ¬í˜„ í•­ëª©\n",
        "1. forward() â€“ ìˆœì „íŒŒ ê³„ì‚°\n",
        "2. compute_loss() â€“ ì†ì‹¤ ê³„ì‚°\n",
        "3. backward() â€“ ì—­ì „íŒŒ ê³„ì‚° (Chain Rule ê¸°ë°˜)\n",
        "4. update_weights() â€“ SGD ê¸°ë°˜ íŒŒë¼ë¯¸í„° ê°±ì‹  ==> ì¤‘ìš”í•¨!!\n",
        "5. í•™ìŠµë¥  ë³€í™” ì‹¤í—˜ (0.001 / 0.01 / 0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb63b68",
      "metadata": {
        "id": "aeb63b68",
        "outputId": "f99c3b1b-0076-4588-a548-dcbe4ac6a7f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.093064599598056\n",
            "Epoch 1000, Loss: 0.6952855339915367\n",
            "Epoch 2000, Loss: 0.6936971588677859\n",
            "Epoch 3000, Loss: 0.6932910022123189\n",
            "Epoch 4000, Loss: 0.6931849512003239\n",
            "Epoch 5000, Loss: 0.6931571110298702\n",
            "Epoch 6000, Loss: 0.6931497921969233\n",
            "Epoch 7000, Loss: 0.6931478674533718\n",
            "Epoch 8000, Loss: 0.6931473612252397\n",
            "Epoch 9000, Loss: 0.6931472280784128\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class XORNetwork:\n",
        "    def __init__(self, input_size=2, hidden_size=4):\n",
        "        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
        "        self.W1 = np.random.randn(input_size, hidden_size)\n",
        "        self.b1 = np.zeros((1, hidden_size))\n",
        "        self.W2 = np.random.randn(hidden_size, 1)\n",
        "        self.b2 = np.zeros((1, 1))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # ìˆœì „íŒŒ\n",
        "        self.z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.a1 = self.relu(self.z1)\n",
        "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
        "        self.a2 = self.sigmoid(self.z2)\n",
        "        return self.a2\n",
        "\n",
        "    def compute_loss(self, Y, Y_pred):\n",
        "        # Binary Cross Entropy ì†ì‹¤\n",
        "        return -np.mean(Y * np.log(Y_pred) + (1 - Y) * np.log(1 - Y_pred))\n",
        "\n",
        "    def backward(self, X, Y):\n",
        "        # ì—­ì „íŒŒ êµ¬í˜„\n",
        "        m = X.shape[0]\n",
        "\n",
        "        # ì¶œë ¥ì¸µ ì˜¤ì°¨\n",
        "        dZ2 = self.a2 - Y\n",
        "        dW2 = (1/m) * np.dot(self.a1.T, dZ2)\n",
        "        db2 = (1/m) * np.sum(dZ2, axis=0)\n",
        "\n",
        "        # ì€ë‹‰ì¸µ ì˜¤ì°¨\n",
        "        dZ1 = np.dot(dZ2, self.W2.T) * (self.z1 > 0)\n",
        "        dW1 = (1/m) * np.dot(X.T, dZ1)\n",
        "        db1 = (1/m) * np.sum(dZ1, axis=0)\n",
        "\n",
        "        return dW1, db1, dW2, db2\n",
        "\n",
        "    def update_weights(self, dW1, db1, dW2, db2, learning_rate=0.01):\n",
        "        # SGD ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
        "        self.W1 -= learning_rate * dW1\n",
        "        self.b1 -= learning_rate * db1\n",
        "        self.W2 -= learning_rate * dW2\n",
        "        self.b2 -= learning_rate * db2\n",
        "\n",
        "# í•™ìŠµ\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "Y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "model = XORNetwork()\n",
        "epochs = 10000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # ìˆœì „íŒŒ\n",
        "    Y_pred = model.forward(X)\n",
        "\n",
        "    # ì†ì‹¤ ê³„ì‚°\n",
        "    loss = model.compute_loss(Y, Y_pred)\n",
        "\n",
        "    # ì—­ì „íŒŒ\n",
        "    dW1, db1, dW2, db2 = model.backward(X, Y)\n",
        "\n",
        "    # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
        "    model.update_weights(dW1, db1, dW2, db2)\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9721a31",
      "metadata": {
        "id": "a9721a31"
      },
      "source": [
        "\n",
        "### âœ… Part 3. ë‹¤ì–‘í•œ ì˜µí‹°ë§ˆì´ì € ì‹¤í—˜ (NumPy êµ¬í˜„ or ì˜ì‚¬ì½”ë“œ)\n",
        "\n",
        "| Optimizer | ì„¤ëª… |\n",
        "|-----------|------|\n",
        "| SGD | ê°€ì¥ ê¸°ë³¸ì ì¸ ê²½ì‚¬í•˜ê°•ë²• |\n",
        "| Momentum | ì´ì „ ê¸°ìš¸ê¸°ë¥¼ ëˆ„ì í•˜ì—¬ ë°˜ë™ íš¨ê³¼ ë¶€ì—¬ |\n",
        "| RMSProp | ê° íŒŒë¼ë¯¸í„°ë³„ ì ì‘ì  í•™ìŠµë¥  ì ìš© |\n",
        "| Adam | Momentum + RMSPropì„ ê²°í•©í•œ ëŒ€í‘œì  ì˜µí‹°ë§ˆì´ì € |\n",
        "\n",
        "\n",
        "ì•„ë˜ ì½”ë“œëŠ” ì–´ë–¤ ë°©ì‹ì˜ ì˜µí‹°ë§ˆì´ì €ì˜ êµ¬í˜„ì¸ì§€ ë‹µí•˜ì‹œì˜¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7f9a508",
      "metadata": {
        "id": "f7f9a508"
      },
      "outputs": [],
      "source": [
        "# ğŸ’¡ ê°„ë‹¨í•œ ì˜µí‹°ë§ˆì´ì € ì˜ì‚¬ì½”ë“œ ì˜ˆì‹œì„.\n",
        "v = 0\n",
        "v = beta * v + (1 - beta) * grad\n",
        "w = w - learning_rate * v\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04fa9ebf",
      "metadata": {
        "id": "04fa9ebf"
      },
      "source": [
        "ëª¨ë©˜í…€ ì˜µí‹°ë§ˆì´ì €"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea19d8e3",
      "metadata": {
        "id": "ea19d8e3"
      },
      "source": [
        "\n",
        "### âœ… Part 4. PyTorch ì…ë¬¸ ê³¼ì œ\n",
        "\n",
        "ì´ì œë¶€í„°ëŠ” AI ë§ˆë²•í•™êµì˜ ê³µì‹ í”„ë ˆì„ì›Œí¬ì¸ **PyTorch**ë¥¼ ë°°ì›ë‹ˆë‹¤!\n",
        "\n",
        "#### ğŸ¯ ë¯¸ì…˜: ìœ„ XOR ë¬¸ì œë¥¼ PyTorchë¡œ ë‹¤ì‹œ í’€ì–´ë³´ì„¸ìš”.\n",
        "- PyTorchë¡œ ê°„ë‹¨í•œ í•™ìŠµ ë£¨í”„ ì˜ˆì œ ì½”ë“œë¥¼ ê²€ìƒ‰í•´ì„œ ì°¾ì•„ì„œ ì§ì ‘ ì‘ì„±í•´ë³´ì„¸ìš”.\n",
        "- torch.nn.Linear, torch.ReLU, torch.Sigmoid, torch.BCELoss ë“± ì‚¬ìš©\n",
        "- torch.optim.SGD, Adam, RMSprop ë“± Optimizerë¡œ ë¹„êµ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "93ee365b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ee365b",
        "outputId": "e23d512c-bca3-42ba-885b-adbc1f3369dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [500/5000], Loss: 0.0221\n",
            "Epoch [1000/5000], Loss: 0.0061\n",
            "Epoch [1500/5000], Loss: 0.0028\n",
            "Epoch [2000/5000], Loss: 0.0016\n",
            "Epoch [2500/5000], Loss: 0.0010\n",
            "Epoch [3000/5000], Loss: 0.0007\n",
            "Epoch [3500/5000], Loss: 0.0005\n",
            "Epoch [4000/5000], Loss: 0.0003\n",
            "Epoch [4500/5000], Loss: 0.0002\n",
            "Epoch [5000/5000], Loss: 0.0002\n",
            "\n",
            "ìµœì¢… ì •í™•ë„: 100.00%\n",
            "\n",
            "ì˜ˆì¸¡ ê²°ê³¼:\n",
            "ì…ë ¥: [0. 0.], ì‹¤ì œê°’: [0.], ì˜ˆì¸¡ê°’: [0.]\n",
            "ì…ë ¥: [0. 1.], ì‹¤ì œê°’: [1.], ì˜ˆì¸¡ê°’: [1.]\n",
            "ì…ë ¥: [1. 0.], ì‹¤ì œê°’: [1.], ì˜ˆì¸¡ê°’: [1.]\n",
            "ì…ë ¥: [1. 1.], ì‹¤ì œê°’: [0.], ì˜ˆì¸¡ê°’: [0.]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# ë°ì´í„° ì¤€ë¹„\n",
        "X = torch.tensor([[0,0], [0,1], [1,0], [1,1]], dtype=torch.float32)\n",
        "Y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "\n",
        "# ëª¨ë¸ ì •ì˜\n",
        "class XORNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XORNetwork, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, 4),  # ì…ë ¥ì¸µ 2ê°œ â†’ ì€ë‹‰ì¸µ 4ê°œ\n",
        "            nn.ReLU(),         # ReLU í™œì„±í™” í•¨ìˆ˜\n",
        "            nn.Linear(4, 1),   # ì€ë‹‰ì¸µ 4ê°œ â†’ ì¶œë ¥ì¸µ 1ê°œ\n",
        "            nn.Sigmoid()       # ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‹œê·¸ëª¨ì´ë“œ\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
        "model = XORNetwork()\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# í•™ìŠµ ë£¨í”„\n",
        "epochs = 5000\n",
        "for epoch in range(epochs):\n",
        "    # ìˆœì „íŒŒ\n",
        "    outputs = model(X)\n",
        "\n",
        "    # ì†ì‹¤ ê³„ì‚°\n",
        "    loss = criterion(outputs, Y)\n",
        "\n",
        "    # ì—­ì „íŒŒ ë° ê°€ì¤‘ì¹˜ ê°±ì‹ \n",
        "    optimizer.zero_grad()  # ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
        "    loss.backward()        # ì—­ì „íŒŒ\n",
        "    optimizer.step()       # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
        "\n",
        "    # ì¼ì • ì£¼ê¸°ë¡œ ì†ì‹¤ ì¶œë ¥\n",
        "    if (epoch + 1) % 500 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# ìµœì¢… ì˜ˆì¸¡ ë° ì •í™•ë„ í‰ê°€\n",
        "with torch.no_grad():\n",
        "    predictions = (model(X) > 0.5).float()\n",
        "    accuracy = (predictions == Y).float().mean()\n",
        "    print(f'\\nìµœì¢… ì •í™•ë„: {accuracy.item() * 100:.2f}%')\n",
        "\n",
        "    # ê²°ê³¼ ì¶œë ¥\n",
        "    print(\"\\nì˜ˆì¸¡ ê²°ê³¼:\")\n",
        "    for i in range(len(X)):\n",
        "        print(f\"ì…ë ¥: {X[i].numpy()}, ì‹¤ì œê°’: {Y[i].numpy()}, ì˜ˆì¸¡ê°’: {predictions[i].numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac0d7cd4",
      "metadata": {
        "id": "ac0d7cd4"
      },
      "source": [
        "\n",
        "## ğŸ ë§ˆë¬´ë¦¬ í€´ì¦ˆ\n",
        "\n",
        "1. í•™ìŠµë¥ ì´ ë„ˆë¬´ í¬ë©´ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œëŠ”?\n",
        "   - a. ê³¼ì í•©  \n",
        "   - b. ì†ì‹¤ ë°œì‚°  \n",
        "   - c. ë” ì •ë°€í•œ í•™ìŠµ  \n",
        "   - d. ì •í™•ë„ê°€ ë¬´ì¡°ê±´ ì˜¬ë¼ê°\n",
        "\n",
        "2. Adam ì˜µí‹°ë§ˆì´ì €ëŠ” ì–´ë–¤ ë‘ ê°€ì§€ ê°œë…ì„ ê²°í•©í•œ ê²ƒì¸ê°€ìš”?\n",
        "   - a. LSTM + GRU  \n",
        "   - b. SGD + Dropout  \n",
        "   - c. Momentum + RMSProp  \n",
        "   - d. SGD + AdaGrad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b, c"
      ],
      "metadata": {
        "id": "58mWqR1gp19L"
      },
      "id": "58mWqR1gp19L"
    },
    {
      "cell_type": "markdown",
      "id": "6271ac05",
      "metadata": {
        "id": "6271ac05"
      },
      "source": [
        "\n",
        "## ğŸ ë³´ë„ˆìŠ¤ ë¯¸ì…˜ (ì„ íƒ)\n",
        "\n",
        "- ì§ì ‘ XORì´ ì•„ë‹Œ make_moons, make_circles ë“±ì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹¤í—˜í•´ë³´ì„¸ìš”.\n",
        "- ì€ë‹‰ì¸µì˜ ë…¸ë“œ ìˆ˜ë¥¼ ë°”ê¿”ê°€ë©° í•™ìŠµ ì„±ëŠ¥ì„ ë¹„êµí•´ë³´ì„¸ìš”.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "98b17132",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98b17132",
        "outputId": "d65ed45b-f62e-4a6d-925e-dc5e6eec6e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MOONS ë°ì´í„°ì…‹ ì‹¤í—˜:\n",
            "ì€ë‹‰ì¸µ [4]: ì •í™•ë„ 85.00%\n",
            "ì€ë‹‰ì¸µ [4, 4]: ì •í™•ë„ 99.00%\n",
            "ì€ë‹‰ì¸µ [8]: ì •í™•ë„ 100.00%\n",
            "ì€ë‹‰ì¸µ [8, 8]: ì •í™•ë„ 100.00%\n",
            "ì€ë‹‰ì¸µ [16]: ì •í™•ë„ 100.00%\n",
            "\n",
            "CIRCLES ë°ì´í„°ì…‹ ì‹¤í—˜:\n",
            "ì€ë‹‰ì¸µ [4]: ì •í™•ë„ 87.00%\n",
            "ì€ë‹‰ì¸µ [4, 4]: ì •í™•ë„ 83.00%\n",
            "ì€ë‹‰ì¸µ [8]: ì •í™•ë„ 85.00%\n",
            "ì€ë‹‰ì¸µ [8, 8]: ì •í™•ë„ 85.00%\n",
            "ì€ë‹‰ì¸µ [16]: ì •í™•ë„ 85.00%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_moons, make_circles\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ë°ì´í„°ì…‹ ìƒì„± ë° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "def prepare_dataset(dataset_type='moons', test_size=0.2):\n",
        "    # ë°ì´í„°ì…‹ ìƒì„±\n",
        "    if dataset_type == 'moons':\n",
        "        X, y = make_moons(n_samples=500, noise=0.15, random_state=42)\n",
        "    else:  # circles\n",
        "        X, y = make_circles(n_samples=500, noise=0.1, random_state=42)\n",
        "\n",
        "    # ë°ì´í„° ë¶„í• \n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=42\n",
        "    )\n",
        "\n",
        "    # í‘œì¤€í™”\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # NumPy â†’ PyTorch í…ì„œ ë³€í™˜\n",
        "    X_train = torch.FloatTensor(X_train)\n",
        "    X_test = torch.FloatTensor(X_test)\n",
        "    y_train = torch.FloatTensor(y_train).unsqueeze(1)\n",
        "    y_test = torch.FloatTensor(y_test).unsqueeze(1)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# ì‹ ê²½ë§ ëª¨ë¸ í´ë˜ìŠ¤\n",
        "class FlexibleNetwork(nn.Module):\n",
        "    def __init__(self, input_size=2, hidden_sizes=[4, 4], output_size=1):\n",
        "        super(FlexibleNetwork, self).__init__()\n",
        "\n",
        "        # ë™ì ìœ¼ë¡œ ë ˆì´ì–´ ìƒì„±\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "\n",
        "        # ì€ë‹‰ì¸µ ì¶”ê°€\n",
        "        for hidden_size in hidden_sizes:\n",
        "            layers.append(nn.Linear(prev_size, hidden_size))\n",
        "            layers.append(nn.ReLU())\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        # ì¶œë ¥ì¸µ\n",
        "        layers.append(nn.Linear(prev_size, output_size))\n",
        "        layers.append(nn.Sigmoid())\n",
        "\n",
        "        # ìˆœì°¨ ëª¨ë¸ ìƒì„±\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# í•™ìŠµ ë° í‰ê°€ í•¨ìˆ˜\n",
        "def train_and_evaluate(X_train, X_test, y_train, y_test, hidden_sizes=[4, 4], lr=0.01, epochs=1000):\n",
        "    # ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
        "    model = FlexibleNetwork(hidden_sizes=hidden_sizes)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # í•™ìŠµ\n",
        "    for epoch in range(epochs):\n",
        "        # ìˆœì „íŒŒ\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "\n",
        "        # ì—­ì „íŒŒ\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # í‰ê°€\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test)\n",
        "        predictions = (test_outputs > 0.5).float()\n",
        "        accuracy = (predictions == y_test).float().mean()\n",
        "\n",
        "    return accuracy.item()\n",
        "\n",
        "# ë°ì´í„°ì…‹ë³„, ì€ë‹‰ì¸µ êµ¬ì¡°ë³„ ì‹¤í—˜\n",
        "def experiment():\n",
        "    # ì‹¤í—˜í•  ë°ì´í„°ì…‹ ìœ í˜•\n",
        "    datasets = ['moons', 'circles']\n",
        "\n",
        "    # ì‹¤í—˜í•  ì€ë‹‰ì¸µ êµ¬ì¡°ë“¤\n",
        "    hidden_layer_configs = [\n",
        "        [4],           # 1ê°œ ì€ë‹‰ì¸µ, 4ë…¸ë“œ\n",
        "        [4, 4],        # 2ê°œ ì€ë‹‰ì¸µ, ê° 4ë…¸ë“œ\n",
        "        [8],           # 1ê°œ ì€ë‹‰ì¸µ, 8ë…¸ë“œ\n",
        "        [8, 8],        # 2ê°œ ì€ë‹‰ì¸µ, ê° 8ë…¸ë“œ\n",
        "        [16],          # 1ê°œ ì€ë‹‰ì¸µ, 16ë…¸ë“œ\n",
        "    ]\n",
        "\n",
        "    # ê²°ê³¼ ì €ì¥\n",
        "    results = {}\n",
        "\n",
        "    # ê° ë°ì´í„°ì…‹ì— ëŒ€í•´ ì‹¤í—˜\n",
        "    for dataset in datasets:\n",
        "        print(f\"\\n{dataset.upper()} ë°ì´í„°ì…‹ ì‹¤í—˜:\")\n",
        "\n",
        "        # ë°ì´í„° ì¤€ë¹„\n",
        "        X_train, X_test, y_train, y_test = prepare_dataset(dataset)\n",
        "\n",
        "        # ê° ì€ë‹‰ì¸µ êµ¬ì¡°ë¡œ ì‹¤í—˜\n",
        "        dataset_results = {}\n",
        "        for config in hidden_layer_configs:\n",
        "            accuracy = train_and_evaluate(\n",
        "                X_train, X_test, y_train, y_test,\n",
        "                hidden_sizes=config\n",
        "            )\n",
        "            dataset_results[str(config)] = accuracy\n",
        "            print(f\"ì€ë‹‰ì¸µ {config}: ì •í™•ë„ {accuracy*100:.2f}%\")\n",
        "\n",
        "        results[dataset] = dataset_results\n",
        "\n",
        "    return results\n",
        "\n",
        "# ì‹¤í—˜ ë° ì‹œê°í™”\n",
        "results = experiment()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2d09400",
      "metadata": {
        "id": "f2d09400"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}